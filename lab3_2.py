# -*- coding: utf-8 -*-
"""Lab3-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XO4yMyzC-dmkEp4NljwHM6DaQ9eB2mxC
"""

pip install transformers

import torch
import pandas as pd
from transformers import BertTokenizer, BertForSequenceClassification, AdamW
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# set up the tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# load the data
df = pd.read_csv('train.csv')

# split the data into prompt tuning set and evaluation benchmark
train_size = int(0.1 * len(df))
df_train = df[:train_size]
df_val = df[train_size:]

# define the prompt engineering techniques to try
prompt_techniques = [
    lambda text: f"disaster: {text}",
    lambda text: f"{text} [SEP] disaster",
    lambda text: f"disaster [SEP] {text}"
]

# set up hyperparameters
epochs = 3
batch_size = 16
learning_rate = 2e-5

# train and evaluate the model with each prompt engineering technique
for i, prompt in enumerate(prompt_techniques):
    # tokenize the data and add special tokens
    train_texts = [prompt(text) for text in df_train['text'].tolist()]
    val_texts = [prompt(text) for text in df_val['text'].tolist()]
    train_encodings = tokenizer(train_texts, truncation=True, padding=True)
    val_encodings = tokenizer(val_texts, truncation=True, padding=True)

    # convert data to tensors
    train_inputs = torch.tensor(train_encodings['input_ids'])
    train_labels = torch.tensor(df_train['target'].tolist())
    train_masks = torch.tensor(train_encodings['attention_mask'])

    val_inputs = torch.tensor(val_encodings['input_ids'])
    val_labels = torch.tensor(df_val['target'].tolist())
    val_masks = torch.tensor(val_encodings['attention_mask'])

    # set up the data loaders
    train_data = TensorDataset(train_inputs, train_masks, train_labels)
    train_sampler = RandomSampler(train_data)
    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)

    val_data = TensorDataset(val_inputs, val_masks, val_labels)
    val_sampler = SequentialSampler(val_data)
    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)

    # set up the model
    model = BertForSequenceClassification.from_pretrained('bert-base-uncased')
    optimizer = AdamW(model.parameters(), lr=learning_rate)

    # train the model
    print(f"\nTraining model with prompt engineering technique {i+1}")
    for epoch in range(epochs):
        print(f"\nEpoch {epoch+1}/{epochs}")
        model.train()
        total_loss = 0
        for step, batch in enumerate(train_dataloader):
            batch_inputs, batch_masks, batch_labels = tuple(t.to(device) for t in batch)
            optimizer.zero_grad()
            outputs = model(batch_inputs, token_type_ids=None, attention_mask=batch_masks, labels=batch_labels)
            loss = outputs[0]
            total_loss += loss.item()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
        avg_train_loss = total_loss / len(train_dataloader)
        print(f"Average training loss: {avg_train_loss:.4f}")

        # evaluate the model on the validation set
        model.eval()
        preds = []
        true_labels = []
        for batch in val_dataloader:
            batch_inputs, batch_masks, batch_labels = tuple(t.to(device) for t in batch)
            with torch.no_grad():
                outputs = model(batch_inputs, token_type_ids=None, attention_mask=batch_masks)

            logits = outputs[0]
            _, batch_pred = torch.max(logits, dim=1)
            preds.extend(batch_pred.tolist())
            true_labels.extend(batch_labels.tolist())

        accuracy = accuracy_score(true_labels, preds)
        precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, preds, average='binary')

        print(f"Accuracy: {accuracy:.4f}")
        print(f"Precision: {precision:.4f}")
        print(f"Recall: {recall:.4f}")
        print(f"F1-score: {f1_score:.4f}")

